{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "# Implementation of clustering aggregation algorithms i) Neighbors ii) Hierarchical iii) KwikSort\n",
    "# Input: People with features, size k\n",
    "# Output: Clusters of size close to k\n",
    "# Method: Clustering Aggregation\n",
    "# Problem Formulation: Given clusterings C1,C2,...,Cm split the aggreement graph into parts of size close to k\n",
    "# (within some approximation) such that you maximize the sum of the weights of the edges within the clusters.\n",
    "# The weight of edge e={u,v} is the fraction of clusterings that put u and v in the same cluster\n",
    "# - maximizes the agreement.\n",
    "# Purpose: Creating teams for hackthegap\n",
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random\n",
    "import itertools\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import chain\n",
    "from itertools import izip\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import jaccard_similarity_score as JS\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input: user ids\n",
    "# Output: Undirected graph where each user is a node and each user has an edge with each other user\n",
    "def initGraph(features):\n",
    "    users = list(features.keys())\n",
    "    # makes graph complete\n",
    "    edges = combinations(users, 2)\n",
    "    \n",
    "    # creating the graph\n",
    "    user_graph=nx.Graph()\n",
    "    user_graph.add_nodes_from(users)\n",
    "    user_graph.add_edges_from(edges)\n",
    "    \n",
    "    return user_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_preprocessing(input_file):\n",
    "    key_names = {}\n",
    "    data = pd.read_csv(input_file)\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    # Renaming columns\n",
    "    data_names = data.rename(columns=\\\n",
    "                        # General Interests\n",
    "                       {'q1-i10::\\rfashion': 'Fashion','q1-i11::\\rsports': 'Sports','q1-i2::\\rpolitics': 'Politics',\\\n",
    "                        'q1-i12::\\rarts': 'Arts','q1-i1::\\rfinance': 'Finance','q1-i3::\\rhealth': 'Health',\\\n",
    "                        'q1-i4::\\rtravel': 'Travel','q1-i5::\\rentertainment': 'Entertainment','q1-i6::\\rmusic': 'Music',\\\n",
    "                        'q1-i7::\\reconomics': 'Economics','q1-i8::\\rsocial issues': 'SocialIssues',\\\n",
    "                        'q1-i9::\\rgaming': 'Gaming','q1-other::\\rother interest': 'OtherGeneralInterest',\\\n",
    "                        \n",
    "                        # Role in Team\n",
    "                        'q2-i1::\\rfront end engineer': 'FrontEnd','q2-i2::\\rback end engineer': 'BackEnd',\\\n",
    "                        'q2-i3::\\rdata scientist': 'DataScientist','q2-i4::\\rdesigner': 'Designer',\\\n",
    "                        'q2-i5::\\rios': 'iOS','q2-i6::\\randriod': 'Android','q2-other::\\rother role': 'OtherRole',\\\n",
    "                        \n",
    "                        # Experience in Different Fields\n",
    "                        'q3-i10::\\rgame dev': 'GameDev','q3-i1::\\rweb app dev': 'WebAppDev',\\\n",
    "                        'q3-i2::\\rmobile app dev': 'MobAppDev','q3-i3::\\rdata mining': 'DataMining',\\\n",
    "                        'q3-i4::\\rmachine intel': 'MachineLearning','q3-i5::\\rcomputer networks': 'ComputerNetworks',\\\n",
    "                        'q3-i6::\\ralgorithm design': 'AlgoDesign','q3-i7::\\rvr/ar': 'VrAr',\\\n",
    "                        'q3-i8::\\rhardware': 'Hardware','q3-i9::\\rIoT': 'IoT',\\\n",
    "                        'q3-other::\\rother experience':'OtherExperience',\\\n",
    "                        \n",
    "                        # Experience in Programming Languages\n",
    "                        'q4-i10::\\rscala': 'Scala','q4-i1::\\rhtml': 'HTML','q4-i2::\\rjs': 'JS','q4-i3::\\rjava': 'Java',\\\n",
    "                        'q4-i4::\\rc++': 'C++','q4-i5::\\rpython': 'Python','q4-i6::\\rruby': 'Ruby','q4-i6::\\rruby': 'Ruby',\\\n",
    "                        'q4-i7::\\rc#': 'C#','q4-i8::\\rsql': 'SQL','q4-i9::\\rswift': 'Swift','q4-i9::\\rswift': 'Swift',\\\n",
    "                        'q4-other::\\rother languages':'OtherLanguages',\\\n",
    "                        \n",
    "                        # Overall Skills Levels\n",
    "                        'q5-i1::\\rcommunication skills': 'CommSkill','q5-i2::\\rdesign skills': 'DesignSkill',\\\n",
    "                        'q5-i3::\\rpresentation skills': 'ReprSkill','q5-i4::\\rproject management skills': 'ProjManSkill',\\\n",
    "                        \n",
    "                        # Motivation\n",
    "                        'q6-i1::\\rhave fun': 'HaveFun','q6-i2::\\rlearn tech': 'LearnTech',\\\n",
    "                        'q6-i3::\\rwin': 'Win','q6-i4::\\rsocialize': 'Socialize','q6-i4::\\rsocialize': 'Socialize',\\\n",
    "                        \n",
    "                        # Goal\n",
    "                        'q7-i1::\\rgreat code': 'GreatCode','q7-i2::\\rgreat concept': 'GreatConcept',\\\n",
    "                        'q7-i3::\\rgreat design': 'GreatDesign','q7-i4::\\rgreat presentation': 'GreatPresentation',\\\n",
    "                        \n",
    "                        # Teams\n",
    "                        'team join::\\rif want to join a team': 'JoinTeam','team::\\rif have team': 'HaveTeam',\\\n",
    "                        'teammates::\\rif looking for teammate': 'LookingForTeammate',\\\n",
    "                        'ft1-ft-other::\\r# of people wanted': '#PeopleNeeded',\\\n",
    "                        'ft2-ft-other::\\rname of team': 'TeamName','ft3-ft-other::\\rteam project focus': 'TeamFocus',\\\n",
    "                        'ft4-ft-other::\\rteam project technology':'TeamTechnology',\\\n",
    "                        'ft5-i1::\\rfront end wanted': 'FrontEndNeeded','ft5-i2::\\rback end wanted': 'BackEndNeeded',\\\n",
    "                        'ft5-i4::\\rdesigner wanted': 'DesignerNeeded','ft5-i5::\\rios person wanted': 'iOSNeeded',\\\n",
    "                        'ft5-i6::\\rother roles wanted': 'OtherNeeded','ft5-i7::\\rweb dev wanted': 'WebDevNeeded',\\\n",
    "                        'ft6-ft-other::\\rteam project experience': 'TeamExperience',\\\n",
    "                        'ft7-ft-other::\\rteam emails': 'TeamEmail',\\\n",
    "                        \n",
    "                        # Id\n",
    "                        'uid': 'Id'})\n",
    "    \n",
    "    # Changing features/skill to binary\n",
    "    data_names['Fashion'] = data_names['Fashion'].map({'Fashion': 1, None: 0})\n",
    "    data_names['Sports'] = data_names['Sports'].map({'Sports': 1, None: 0})\n",
    "    data_names['Arts'] = data_names['Arts'].map({'Arts': 1, None: 0})\n",
    "    data_names['Finance'] = data_names['Finance'].map({'Finance': 1, None: 0})\n",
    "    data_names['Health'] = data_names['Health'].map({'Health': 1, None: 0})\n",
    "    data_names['Travel'] = data_names['Travel'].map({'Travel': 1, None: 0})\n",
    "    data_names['Entertainment'] = data_names['Entertainment'].map({'Entertainment': 1, None: 0})\n",
    "    data_names['Music'] = data_names['Music'].map({'Music': 1, None: 0})\n",
    "    data_names['Economics'] = data_names['Economics'].map({'Economics': 1, None: 0})\n",
    "    data_names['SocialIssues'] = data_names['SocialIssues'].map({'Social Issues': 1, None: 0})\n",
    "    data_names['Gaming'] = data_names['Gaming'].map({'Gaming': 1, None: 0})\n",
    "    # data_names['OtherGeneralInterest'] = data_names['OtherGeneralInterest'].map({'OtherGeneralInterest': 1, None: 0})\n",
    "    \n",
    "    data_names['FrontEnd'] = data_names['FrontEnd'].map({'Front-end Engineer': 1, None: 0})\n",
    "    data_names['BackEnd'] = data_names['BackEnd'].map({'Back-end Engineer': 1, None: 0})\n",
    "    data_names['DataScientist'] = data_names['DataScientist'].map({'Data Scientist': 1, None: 0})\n",
    "    data_names['Designer'] = data_names['Designer'].map({'Designer': 1, None: 0})\n",
    "    data_names['iOS'] = data_names['iOS'].map({'iOS': 1, None: 0})\n",
    "    data_names['Android'] = data_names['Android'].map({'Android': 1, None: 0})\n",
    "    # data_names['OtherRole'] = data_names['OtherRole'].map({'OtherRole': 1, None: 0})\n",
    "    \n",
    "    data_names['GameDev'] = data_names['GameDev'].map({None: 1,'No experience': 1,'Some experience': 2,'Completed one project/course': 3,\\\n",
    "                                                       'Completed multiple projects/courses': 4})\n",
    "    data_names['WebAppDev'] = data_names['WebAppDev'].map({None: 1,'No experience': 1,'Some experience': 2,'Completed one project/course': 3,\\\n",
    "                                                       'Completed multiple projects/courses': 4})\n",
    "    data_names['MobAppDev'] = data_names['MobAppDev'].map({None: 1,'No experience': 1,'Some experience': 2,'Completed one project/course': 3,\\\n",
    "                                                       'Completed multiple projects/courses': 4})\n",
    "    data_names['DataMining'] = data_names['DataMining'].map({None: 1,'No experience': 1,'Some experience': 2,'Completed one project/course': 3,\\\n",
    "                                                       'Completed multiple projects/courses': 4})\n",
    "    data_names['MachineLearning'] = data_names['MachineLearning'].map({None: 1,'No experience': 1,'Some experience': 2,'Completed one project/course': 3,\\\n",
    "                                                       'Completed multiple projects/courses': 4})\n",
    "    data_names['ComputerNetworks'] = data_names['ComputerNetworks'].map({None: 1,'No experience': 1,'Some experience': 2,'Completed one project/course': 3,\\\n",
    "                                                       'Completed multiple projects/courses': 4})\n",
    "    data_names['AlgoDesign'] = data_names['AlgoDesign'].map({None: 1,'No experience': 1,'Some experience': 2,'Completed one project/course': 3,\\\n",
    "                                                       'Completed multiple projects/courses': 4})\n",
    "    data_names['VrAr'] = data_names['VrAr'].map({None: 1,'No experience': 1,'Some experience': 2,'Completed one project/course': 3,\\\n",
    "                                                       'Completed multiple projects/courses': 4})\n",
    "    data_names['Hardware'] = data_names['Hardware'].map({None: 1,'No experience': 1,'Some experience': 2,'Completed one project/course': 3,\\\n",
    "                                                       'Completed multiple projects/courses': 4})\n",
    "    data_names['IoT'] = data_names['IoT'].map({None: 1,'No experience': 1,'Some experience': 2,'Completed one project/course': 3,\\\n",
    "                                                       'Completed multiple projects/courses': 4})\n",
    "    # data_names['OtherRole'] = data_names['OtherRole'].map({None: 1,'No experience': 1,'Some experience': 2,'Completed one project/course': 3,\\\n",
    "    #                                                    'Completed multiple projects/courses': 4})\n",
    "    \n",
    "    data_names['Scala'] = data_names['Scala'].map({None: 1,'No experience': 1,'Some experience': 2,'Completed one project/course': 3,\\\n",
    "                                                       'Completed multiple projects/courses': 4})\n",
    "    data_names['HTML'] = data_names['HTML'].map({None: 1,'No experience': 1,'Some experience': 2,'Completed one project/course': 3,\\\n",
    "                                                       'Completed multiple projects/courses': 4})\n",
    "    data_names['JS'] = data_names['JS'].map({None: 1,'No experience': 1,'Some experience': 2,'Completed one project/course': 3,\\\n",
    "                                                       'Completed multiple projects/courses': 4})\n",
    "    data_names['Java'] = data_names['Java'].map({None: 1,'No experience': 1,'Some experience': 2,'Completed one project/course': 3,\\\n",
    "                                                       'Completed multiple projects/courses': 4})\n",
    "    data_names['C++'] = data_names['C++'].map({None: 1,'No experience': 1,'Some experience': 2,'Completed one project/course': 3,\\\n",
    "                                                       'Completed multiple projects/courses': 4})\n",
    "    data_names['Python'] = data_names['Python'].map({None: 1,'No experience': 1,'Some experience': 2,'Completed one project/course': 3,\\\n",
    "                                                       'Completed multiple projects/courses': 4})\n",
    "    data_names['Ruby'] = data_names['Ruby'].map({None: 1,'No experience': 1,'Some experience': 2,'Completed one project/course': 3,\\\n",
    "                                                       'Completed multiple projects/courses': 4})\n",
    "    data_names['C#'] = data_names['C#'].map({None: 1,'No experience': 1,'Some experience': 2,'Completed one project/course': 3,\\\n",
    "                                                       'Completed multiple projects/courses': 4})\n",
    "    data_names['SQL'] = data_names['SQL'].map({None: 1,'No experience': 1,'Some experience': 2,'Completed one project/course': 3,\\\n",
    "                                                       'Completed multiple projects/courses': 4})\n",
    "    data_names['Swift'] = data_names['Swift'].map({None: 1,'No experience': 1,'Some experience': 2,'Completed one project/course': 3,\\\n",
    "                                                       'Completed multiple projects/courses': 4})\n",
    "    # data_names['OtherLanguages'] = data_names['OtherLanguages'].map({None: 1,'No experience': 1,'Some experience': 2,'Completed one project/course': 3,\\\n",
    "    #                                                    'Completed multiple projects/courses': 4})\n",
    "    \n",
    "    data_names['CommSkill'] = data_names['CommSkill'].map({None: 0,1:1,2:2,3:3,4:4,5:5})\n",
    "    data_names['DesignSkill'] = data_names['DesignSkill'].map({None: 0,1:1,2:2,3:3,4:4,5:5})\n",
    "    data_names['ReprSkill'] = data_names['ReprSkill'].map({None: 0,1:1,2:2,3:3,4:4,5:5})\n",
    "    data_names['ProjManSkill'] = data_names['ProjManSkill'].map({None: 0,1:1,2:2,3:3,4:4,5:5})\n",
    "\n",
    "    data_names['HaveFun'] = data_names['HaveFun'].map({None: 0,1:1,2:2,3:3,4:4,5:5})\n",
    "    data_names['LearnTech'] = data_names['LearnTech'].map({None: 0,1:1,2:2,3:3,4:4,5:5})\n",
    "    data_names['Win'] = data_names['Win'].map({None: 0,1:1,2:2,3:3,4:4,5:5})\n",
    "    data_names['Socialize'] = data_names['Socialize'].map({None: 0,1:1,2:2,3:3,4:4,5:5})\n",
    "    \n",
    "    data_names['GreatCode'] = data_names['GreatCode'].map({None: 0,1:1,2:2,3:3,4:4,5:5})\n",
    "    data_names['GreatConcept'] = data_names['GreatConcept'].map({None: 0,1:1,2:2,3:3,4:4,5:5})\n",
    "    data_names['GreatDesign'] = data_names['GreatDesign'].map({None:0,1:1,2:2,3:3,4:4,5:5})\n",
    "    data_names['GreatPresentation'] = data_names['GreatPresentation'].map({None: 0,1:1,2:2,3:3,4:4,5:5})\n",
    "    \n",
    "    data_names = data_names.fillna(0)\n",
    "    # Dropping columns not needed\n",
    "    data = data_names[['Id','Fashion','Sports','Arts','Finance','Health','Travel','Entertainment','Music','Economics',\\\n",
    "                       'SocialIssues','Gaming',\\\n",
    "                       'FrontEnd','BackEnd','DataScientist','Designer','iOS','Android',\\\n",
    "                       'GameDev','WebAppDev','MobAppDev','DataMining','MachineLearning','ComputerNetworks','AlgoDesign',\\\n",
    "                       'VrAr','Hardware','IoT',\\\n",
    "                       'Scala','HTML','JS','Java','C++','Python','Ruby','C#','SQL','Swift',\\\n",
    "                       'CommSkill','DesignSkill','ReprSkill','ProjManSkill',\\\n",
    "                       'HaveFun','LearnTech','Win','Socialize',\\\n",
    "                       'GreatCode','GreatConcept','GreatDesign','GreatPresentation']]\n",
    "    \n",
    "    # technology_list = data['Technology'].tolist()\n",
    "    # unique_technologies = list(set(technology_list))\n",
    "    \n",
    "    # Dictionary with key: person id and value: dictionary of features\n",
    "    person_data = {}; skills = []\n",
    "    for index, row in data.iterrows():\n",
    "        interests = []; roles = []; \n",
    "        key = row['Id'];\n",
    "        \n",
    "        # General Interests\n",
    "        if row['Fashion']==1:\n",
    "            interests.append('Fashion') \n",
    "        if row['Sports']==1:\n",
    "            interests.append('Sports')\n",
    "        if row['Arts']==1:\n",
    "            interests.append('Arts')\n",
    "        if row['Finance']==1:\n",
    "            interests.append('Finance')\n",
    "        if row['Health']==1:\n",
    "            interests.append('Health')\n",
    "        if row['Travel']==1:\n",
    "            interests.append('Travel')\n",
    "        if row['Entertainment']==1:\n",
    "            interests.append('Entertainment')\n",
    "        if row['Music']==1:\n",
    "            interests.append('Music')\n",
    "        if row['Economics']==1:\n",
    "            interests.append('Economics')\n",
    "        if row['SocialIssues']==1:\n",
    "            interests.append('SocialIssues')\n",
    "        if row['Gaming']==1:\n",
    "            interests.append('Gaming')\n",
    "            \n",
    "        # Role in Team\n",
    "        if row['FrontEnd']==1:\n",
    "            roles.append('FrontEnd') \n",
    "        if row['BackEnd']==1:\n",
    "            roles.append('BackEnd')\n",
    "        if row['DataScientist']==1:\n",
    "            roles.append('DataScientist')\n",
    "        if row['Designer']==1:\n",
    "            roles.append('Designer')\n",
    "        if row['iOS']==1:\n",
    "            roles.append('iOS')\n",
    "        if row['Android']==1:\n",
    "            roles.append('Android')\n",
    "            \n",
    "        # Experience in Different Fields\n",
    "        fields = {'GameDev':row['GameDev'],'WebAppDev':row['WebAppDev'],'MobAppDev':row['MobAppDev'],\\\n",
    "                  'DataMining':row['DataMining'],'MachineLearning':row['MachineLearning'],\\\n",
    "                  'ComputerNetworks':row['ComputerNetworks'],'AlgoDesign':row['AlgoDesign'],\\\n",
    "                  'VrAr':row['VrAr'],'Hardware':row['Hardware'],'IoT':row['IoT']}\n",
    "\n",
    "\n",
    "        # Experience in Programming Languages\n",
    "        languages = {'Scala':row['Scala'],'HTML':row['HTML'],'JS':row['JS'],\\\n",
    "                  'Java':row['Java'],'C++':row['C++'],\\\n",
    "                  'Python':row['Python'],'Ruby':row['Ruby'],\\\n",
    "                  'C#':row['C#'],'SQL':row['SQL'],'Swift':row['Swift']}                                                                            \n",
    "            \n",
    "        # Overall Skills Levels\n",
    "        overall_skills = {'CommSkill':row['CommSkill'],'DesignSkill':row['DesignSkill'],\\\n",
    "                          'ReprSkill':row['ReprSkill'],'ProjManSkill':row['ProjManSkill']}\n",
    "        \n",
    "        # Motivation\n",
    "        motivation = {'HaveFun':row['HaveFun'],'LearnTech':row['LearnTech'],\\\n",
    "                      'Win':row['Win'],'Socialize':row['Socialize']}\n",
    "\n",
    "        # Goal\n",
    "        goal = {'GreatCode':row['GreatCode'],'GreatConcept':row['GreatConcept'],\\\n",
    "                      'GreatDesign':row['GreatDesign'],'GreatPresentation':row['GreatPresentation']}\n",
    "        \n",
    "        value = {'interests':interests,'roles':roles,'fields':fields,'languages':languages,\\\n",
    "                'overall_skills':overall_skills,'motivation':motivation,'goal':goal}\n",
    "        \n",
    "        person_data[key] = value\n",
    "        \n",
    "\n",
    "    # Extracting features 1) General interests * 11 2) Roles * 6 3) Experience in fields * 10\n",
    "    #                     4) Experience in languages * 10 5) Overall skills * 4\n",
    "    #                     6) Motivation * 4 7) Goal * 4\n",
    "    \n",
    "    # create dictionary of person : [features]\n",
    "    data = data.fillna(0)\n",
    "    features = \\\n",
    "            {data.loc[idx, 'Id']: [data.loc[idx, 'Fashion'], data.loc[idx, 'Sports'], data.loc[idx, 'Arts'],\\\n",
    "                                   data.loc[idx, 'Finance'], data.loc[idx, 'Health'], data.loc[idx, 'Travel'],\\\n",
    "                                   data.loc[idx, 'Entertainment'], data.loc[idx, 'Music'], data.loc[idx, 'Economics'],\\\n",
    "                                   data.loc[idx, 'SocialIssues'], data.loc[idx, 'Gaming'], data.loc[idx, 'FrontEnd'],\\\n",
    "                                   data.loc[idx, 'BackEnd'], data.loc[idx, 'DataScientist'], data.loc[idx, 'Designer'],\\\n",
    "                                   data.loc[idx, 'iOS'], data.loc[idx, 'Android'], data.loc[idx, 'GameDev'],\\\n",
    "                                   data.loc[idx, 'WebAppDev'], data.loc[idx, 'MobAppDev'], data.loc[idx, 'DataMining'],\\\n",
    "                                   data.loc[idx, 'MachineLearning'], data.loc[idx, 'ComputerNetworks'], data.loc[idx, 'AlgoDesign'],\\\n",
    "                                   data.loc[idx, 'VrAr'], data.loc[idx, 'Hardware'], data.loc[idx, 'IoT'],\\\n",
    "                                   data.loc[idx, 'Scala'], data.loc[idx, 'HTML'], data.loc[idx, 'JS'],\\\n",
    "                                   data.loc[idx, 'Java'], data.loc[idx, 'C++'], data.loc[idx, 'Python'],\\\n",
    "                                   data.loc[idx, 'Ruby'], data.loc[idx, 'C#'], data.loc[idx, 'SQL'],\\\n",
    "                                   data.loc[idx, 'Swift'], data.loc[idx, 'CommSkill'], data.loc[idx, 'DesignSkill'],\\\n",
    "                                   data.loc[idx, 'ReprSkill'], data.loc[idx, 'ProjManSkill'], data.loc[idx, 'HaveFun'],\\\n",
    "                                   data.loc[idx, 'LearnTech'], data.loc[idx, 'Win'], data.loc[idx, 'Socialize'],\\\n",
    "                                   data.loc[idx, 'GreatCode'], data.loc[idx, 'GreatConcept'], data.loc[idx, 'GreatDesign'],\\\n",
    "                                   data.loc[idx, 'GreatPresentation']] \\\n",
    "                                   for idx in range(data.shape[0])}\n",
    "    \n",
    "    # for key, value in features.iteritems():\n",
    "        # print len(value)\n",
    "    # print 'Features:',features\n",
    "    # print '*'*500\n",
    "    # print 'Person data:',person_data\n",
    "    # print '*'*500\n",
    "    return data, features, person_data,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_computation(weight_metric,features_user1,features_user2):\n",
    "    \n",
    "    weight = float(\"inf\")\n",
    "    if weight_metric == 'difference':\n",
    "        weight = 1 - (abs(features_user1 - features_user2)/float(2))\n",
    "    elif weight_metric == 'jaccard':\n",
    "        intersect = len(list(set(features_user1) & set(features_user2)))\n",
    "        union = len(list(set(features_user1) | set(features_user2)))\n",
    "        weight = intersect / float(union)\n",
    "    elif weight_metric == 'same':\n",
    "        if isinstance(features_user1,int):\n",
    "            if features_user1 == features_user2:\n",
    "                weight = 1\n",
    "            else:\n",
    "                weight = 0\n",
    "        else:\n",
    "            idx1 = features_user1.index(1)\n",
    "            idx2 = features_user2.index(1)\n",
    "            if idx1 == idx2:\n",
    "                weight = 1\n",
    "            else:\n",
    "                weight = 0\n",
    "    elif weight_metric == 'euclidean':\n",
    "        dst = distance.euclidean(features_user1,features_user2)\n",
    "        weight = 1 /float(1 + dst)\n",
    "            \n",
    "    return weight      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Input: feature vectors\n",
    "# Output: weighted clusterings based on features, mapping between user pair and weights in different clusterings\n",
    "# Note!! 0-10: General Interests, 11-16: Role in team, 17-26: Exp in different fields, \n",
    "# 27-36: Exp in Programing Languages, 37-40: Skills levels, 41-44: Motivation, 45-48: Goal. \n",
    "# that lead to the corresponding number of clusterings i.e. 7\n",
    "\n",
    "def create_clusterings(features,user_graph):\n",
    "    \n",
    "    clusterings = []\n",
    "    clustering_weights = {}\n",
    "\n",
    "    # indexes that show where each feature begins, for instance\n",
    "    # general interests range from 0-10\n",
    "    indexes = [0,11,17,27,37,41,45]\n",
    "    weight_metrics = ['jaccard','jaccard','euclidean','euclidean','euclidean','euclidean','euclidean']\n",
    "    \n",
    "    # creating the weights for each clustering  - all weights range from 0 to 1\n",
    "    # general interests (jaccard): weight = Jaccard(set1,set2)\n",
    "    # role in team (jaccard): Jaccard(set1,set2)\n",
    "    # experience in different fields (euclidean similarity): 1/1+dst\n",
    "    # experience in programming languages (euclidean similarity): 1/1+dst\n",
    "    # experience in overall skills levels (euclidean similarity): 1/1+dst\n",
    "    # motivation (euclidean similarity): 1/1+dst\n",
    "    # goal (euclidean similarity): 1/1+dst\n",
    "    \n",
    "    counter = 0; values = []\n",
    "    length_indexes = len(indexes)-1\n",
    "    for idx, value in enumerate(indexes):\n",
    "        user_graph_copy = nx.Graph(user_graph)\n",
    "        \n",
    "        weight_metric = weight_metrics[idx]\n",
    "        for user1,user2 in user_graph_copy.edges(data=False):\n",
    "            key = (user1,user2)\n",
    "            if idx != length_indexes:\n",
    "                features_user1 = features[user1][value:indexes[idx+1]]\n",
    "                features_user2 = features[user2][value:indexes[idx+1]]\n",
    "            else:\n",
    "                length_features = len(features[user1])\n",
    "                features_user1 = features[user1][value:length_features+1]\n",
    "                features_user2 = features[user2][value:length_features+1]\n",
    "                \n",
    "            weight = weight_computation(weight_metric,features_user1,features_user2)\n",
    "            user_graph_copy.edge[user1][user2]['weight'] = weight\n",
    "                \n",
    "            if key in clustering_weights:\n",
    "                clustering_weights[key].append(weight)\n",
    "            else:\n",
    "                clustering_weights[key] = [];\n",
    "                clustering_weights[key].append(weight)\n",
    "                              \n",
    "        clusterings.append(user_graph_copy)\n",
    "        \n",
    "    return clusterings, clustering_weights    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Aggrement_Graph: Creating the aggreement graph used by the proposed team formation algorithms \n",
    "# Input: data\n",
    "# Output: Aggreement Graph \n",
    "# Note!! 0-10: General Interests, 11-16: Role in team, 17-26: Exp in different fields, \n",
    "# 27-36: Exp in Programing Languages, 37-40: Skills levels, 41-44: Motivation, 45-48: Goal. \n",
    "# These are the distinct different features\n",
    "def similarity_graph(features):\n",
    "    print 'Creating aggreement graph'\n",
    "    \n",
    "    # creating initial unweighted graph\n",
    "    user_graph = initGraph(features)\n",
    "    aggreement_graph = nx.Graph(user_graph)\n",
    "    \n",
    "    (clusterings, clustering_weights) = create_clusterings(features,user_graph)\n",
    "    \n",
    "    for key,value in clustering_weights.iteritems():\n",
    "        user1 = key[0]; user2 = key[1]\n",
    "        value[0] = value[0]*10\n",
    "        value[2] = value[2]*5\n",
    "        value[3] = value[3]*5\n",
    "        value[5] = value[5]*5\n",
    "        value[6] = value[6]*10\n",
    "        \n",
    "        weight = sum(value)/float(len(value)+34)\n",
    "        aggreement_graph.edge[user1][user2]['weight'] = weight\n",
    "    \n",
    "    for u in aggreement_graph.nodes():\n",
    "        aggreement_graph.node[u]['size'] = 1\n",
    "    \n",
    "    return aggreement_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def merge_nodes(u,v,Merge_AGraph,algo):\n",
    "    size = float(\"inf\")\n",
    "    new_node = ()\n",
    "        \n",
    "    # 1) create a new cluster node with a) updated cluster nodes (u+v), b) updated cluster size\n",
    "    if algo == 'kwiksort':\n",
    "        if isinstance(v,tuple):\n",
    "            size = len(v) + 1\n",
    "            new_node = (v,u)\n",
    "            new_node = tuple(list(new_node[0]) + [new_node[1]])\n",
    "        else:\n",
    "            size = 2\n",
    "            new_node = (v,u)\n",
    "            \n",
    "    elif algo == 'hierarchical':\n",
    "        new_node = (v,u)\n",
    "        new_node = tuple(chain(*(i if isinstance(i, tuple) else (i,) for i in new_node)))\n",
    "        size = len(new_node)\n",
    "        \n",
    "    # adding new node to graph    \n",
    "    Merge_AGraph.add_node(new_node)\n",
    "    Merge_AGraph.node[new_node]['size'] = size\n",
    "    # 2) for each neighbor of u and v compute average weight edge - Should not matter \n",
    "    # if it is u or v because it is a complete graph\n",
    "\n",
    "    neighbors_u = Merge_AGraph.neighbors(u)\n",
    "    \n",
    "    for neighbor in neighbors_u:\n",
    "        flag = False\n",
    "        if Merge_AGraph.has_edge(u,neighbor):\n",
    "            weight_u = Merge_AGraph.edge[u][neighbor]['weight']\n",
    "        else:\n",
    "            flag = True\n",
    "        if Merge_AGraph.has_edge(neighbor,v):    \n",
    "            weight_v = Merge_AGraph.edge[neighbor][v]['weight']\n",
    "        else:\n",
    "            flag = True\n",
    "\n",
    "        if flag == False:\n",
    "            new_weight = (weight_u+weight_v)/float(2)\n",
    "            Merge_AGraph.add_edge(new_node,neighbor) \n",
    "            Merge_AGraph.edge[new_node][neighbor]['weight'] = new_weight\n",
    "\n",
    "    \n",
    "    # 3) remove old nodes u,v\n",
    "    Merge_AGraph.remove_node(v)\n",
    "    Merge_AGraph.remove_node(u)\n",
    "\n",
    "    return Merge_AGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hierarchical\n",
    "# Input: Aggreement Graph, k\n",
    "# Output: m clusters\n",
    "def constrained_hierarchical(AGraph,k): \n",
    "    li = []\n",
    "    Copy_AGraph = nx.Graph(AGraph)\n",
    "    removed_nodes = {}\n",
    "    weight_flag = False\n",
    "    while Copy_AGraph.edges and weight_flag == False:\n",
    "        max_edge_weight = -float(\"inf\")\n",
    "        for (u,v) in Copy_AGraph.edges(data=False):\n",
    "            size1 = Copy_AGraph.node[u]['size']\n",
    "            size2 = Copy_AGraph.node[v]['size']\n",
    "            weight = Copy_AGraph.edge[u][v]['weight']\n",
    "                \n",
    "            if weight > max_edge_weight and size1+size2 <= k:\n",
    "                new_edge = (u,v)\n",
    "                max_edge_weight = weight\n",
    "        \n",
    "        u = new_edge[0]; v = new_edge[1]\n",
    "        if max_edge_weight != -float(\"inf\"):\n",
    "            Copy_AGraph  = merge_nodes(u,v,Copy_AGraph,'hierarchical')\n",
    "            for (u,data) in Copy_AGraph.nodes(data=True):\n",
    "                size = data['size']\n",
    "                if size == k:\n",
    "                    neighbors = Copy_AGraph.edges(u,data=True)\n",
    "                    removed_nodes[u] = neighbors\n",
    "\n",
    "        else:\n",
    "            weight_flag = True\n",
    "    \n",
    "    return Copy_AGraph.nodes(data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hierarchical\n",
    "# Input: Aggreement Graph, k\n",
    "# Output: m clusters\n",
    "def unconstrained_hierarchical(AGraph,k): \n",
    "    Copy_AGraph = nx.Graph(AGraph)\n",
    "    removed_nodes = {}\n",
    "    weight_flag = False\n",
    "    while Copy_AGraph.edges and weight_flag == False:\n",
    "        max_edge_weight = -float(\"inf\")\n",
    "        for (u,v) in Copy_AGraph.edges(data=False):\n",
    "            size1 = Copy_AGraph.node[u]['size']\n",
    "            size2 = Copy_AGraph.node[v]['size']\n",
    "            weight = Copy_AGraph.edge[u][v]['weight']\n",
    "            if weight > max_edge_weight:\n",
    "                new_edge = (u,v)\n",
    "                max_edge_weight = weight\n",
    "        \n",
    "        u = new_edge[0]; v = new_edge[1]\n",
    "        if max_edge_weight != -float(\"inf\") and max_edge_weight >= 0.5:\n",
    "            Copy_AGraph  = merge_nodes(u,v,Copy_AGraph,'hierarchical')\n",
    "            for (u,data) in Copy_AGraph.nodes(data=True):\n",
    "                size = data['size']\n",
    "                if size == k:\n",
    "                    neighbors = Copy_AGraph.edges(u,data=True)\n",
    "                    removed_nodes[u] = neighbors\n",
    "\n",
    "        else:\n",
    "            weight_flag = True\n",
    "        \n",
    "    for node in Copy_AGraph.nodes(data=False):\n",
    "        if not isinstance(node,tuple):\n",
    "            Copy_AGraph.remove_node(node)\n",
    "            new_node = (node,)\n",
    "            Copy_AGraph.add_node(new_node)\n",
    "            \n",
    "\n",
    "    return Copy_AGraph.nodes(data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Neighbors \n",
    "# Input: Aggreement Graph, k\n",
    "# Output: m clusters \n",
    "\n",
    "# TODO\n",
    "def neighbors(AGraph,k):\n",
    "    print 'Running neighbors algorithm'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KwikSort\n",
    "# Input: Aggreement Graph, k\n",
    "# Output: m clusters\n",
    "def kwiksort(AGraph,k,person_ids,pairs,num_iter,threshold):\n",
    "    \n",
    "    solution = []\n",
    "\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_to_output(solution,features,idx_RMSD,idx_a,idx_s,output_file):\n",
    "    data = []; names_team = []\n",
    "    counter = 1\n",
    "    # print 'Solution in write to output:',solution\n",
    "    max_cluster = -float(\"inf\")\n",
    "    for cluster in solution:\n",
    "        if len(cluster) > max_cluster:\n",
    "            max_cluster = len(cluster)\n",
    "\n",
    "    for idx,cluster in enumerate(solution):\n",
    "        feature_list = []; row = {};\n",
    "        for person in cluster:\n",
    "            features_per_person = features[person]\n",
    "            feature_list.append(features_per_person)\n",
    "            \n",
    "        feature_list += [''] * (max_cluster - len(feature_list)+1)\n",
    "        row['cluster'] = counter  \n",
    "        row['cluster size'] = len(cluster)\n",
    "        row['person ids'] = cluster\n",
    "        row['Avg RMSD'] = idx_RMSD[idx]\n",
    "        row['Avg A'] = idx_a[idx]\n",
    "        row['Avg S'] = idx_s[idx]\n",
    "        for i in range(max_cluster+1):\n",
    "            column_value = 'Member '+str(i)\n",
    "            row[column_value] = feature_list[i]\n",
    "            \n",
    "        data.append(row)   \n",
    "        counter+=1\n",
    "        \n",
    "    output_solution = pd.DataFrame(data=data)\n",
    "    person_ids = output_solution['person ids']; cluster_size = output_solution['cluster size']; \\\n",
    "    cluster = output_solution['cluster']\n",
    "    output_solution.drop(labels=['person ids','cluster size','cluster'], axis=1,inplace = True)\n",
    "    output_solution.insert(0, 'cluster', cluster)\n",
    "    output_solution.insert(1, 'cluster size', cluster_size)\n",
    "    output_solution.insert(2, 'person ids', person_ids)\n",
    "    \n",
    "    output_solution.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findsubsets(features,m):\n",
    "    person_ids = list(features.keys())\n",
    "    return list(itertools.combinations(person_ids, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Computes the centroid from a list of data points\n",
    "def mean(a):\n",
    "    return sum(a) / float(len(a))\n",
    "\n",
    "def centroid(l):\n",
    "    c = map(mean, zip(*l))  \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_small_clusters(min_team_size,max_team_size,solution,features):\n",
    "    new_solution = []\n",
    "    distribute = {}; remove_cluster = []; spacious_clusters = []\n",
    "    \n",
    "    # creating a distribution of all clusters and \n",
    "    for idx,cluster in enumerate(solution):\n",
    "        if len(cluster) < min_team_size:\n",
    "            for person in cluster:\n",
    "                features_per_person = features[person]\n",
    "                distribute[person] = features_per_person\n",
    "            remove_cluster.append(idx)\n",
    "        elif len(cluster) == max_team_size:\n",
    "            spacious_clusters.append(cluster)\n",
    "            remove_cluster.append(idx)\n",
    "    \n",
    "    subtract = 0\n",
    "    for idx in remove_cluster:\n",
    "        del solution[idx-subtract]\n",
    "        subtract+=1\n",
    "    \n",
    "    cluster_centroids = {}; cluster_lengthts = {}\n",
    "    for idx,team in enumerate(solution):\n",
    "        team_features = []; rmsds = []\n",
    "        for member in team:\n",
    "            team_features.append(features[member])\n",
    "        # team_features = np.array(team_features)\n",
    "        # team_features = team_features[:,8:15].tolist()\n",
    "        c = centroid(team_features)  \n",
    "        cluster_centroids[idx] = c\n",
    "        cluster_lengthts[idx] = len(team)\n",
    "\n",
    "    \n",
    "    # print 'Persons to distribute:',distribute\n",
    "    for person, value in distribute.iteritems():\n",
    "        features_per_person = features[person]\n",
    "        min_dist = float(\"inf\"); cluster_id = float(\"inf\")\n",
    "        for cluster, centroid_values in cluster_centroids.iteritems():\n",
    "            dst = distance.euclidean(features_per_person,centroid_values)\n",
    "            if dst < min_dist and cluster_lengthts[cluster] < max_team_size:\n",
    "                min_dist = dst\n",
    "                cluster_id = cluster\n",
    "                \n",
    "        # print 'Min cluster id:',cluster_id \n",
    "        # print 'Appending to cluster:',solution[cluster_id],'person:',person,'with features:',features[person]\n",
    "        cluster_lengthts[cluster_id]+=1\n",
    "        solution[cluster_id] = solution[cluster_id] + (person,)\n",
    "\n",
    "    # print 'Solution after:',solution\n",
    "            \n",
    "    solution = solution + spacious_clusters                  \n",
    "    return solution\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# constrained_KwikSort\n",
    "# Input: Aggreement Graph, k, threshold as percentile\n",
    "# Output: m clusters\n",
    "\n",
    "def constrained_kwiksort(AGraph,k,threshold):\n",
    "    solution = [] \n",
    "    while len(solution)==0:\n",
    "        # print('try kwiksort')\n",
    "        solution = kwiksort_helper(AGraph.copy(),k,threshold,True)\n",
    "    print('feasible solution found')\n",
    "    return solution\n",
    "\n",
    "def constrained_kwiksort_not_random(AGraph,k,threshold):\n",
    "    solution = [] \n",
    "    while len(solution)==0:\n",
    "        # print('try kwiksort')\n",
    "        solution = kwiksort_helper(AGraph.copy(),k,threshold,False)\n",
    "    print('feasible solution found')\n",
    "    return solution\n",
    "\n",
    "# unconstrained_KwikSort\n",
    "# Input: Aggreement Graph, k, threshold\n",
    "# Output: m clusters\n",
    "def unconstrained_kwiksort(AGraph,k,threshold):\n",
    "    # solution should be a list of lists or tuples\n",
    "    solution= []\n",
    "    \n",
    "    ## Fill in here\n",
    "    while (AGraph.number_of_nodes()>k):\n",
    "            \n",
    "        u = AGraph.nodes()[random.randint(0,AGraph.number_of_nodes()-1)]\n",
    "        neighbors = AGraph.neighbors(u)\n",
    "        weights = {}\n",
    "        for neighbor in neighbors:\n",
    "            weights[neighbor] = AGraph.edge[u][neighbor]['weight']\n",
    "        weights = sorted(weights.iteritems(), key=lambda (k,v): (v,k))[::-1]\n",
    "        \n",
    "        cluster = []\n",
    "        for i in range(len(weights)):\n",
    "            if weights[i][1] > threshold:\n",
    "                cluster.append(weights[i][0])  \n",
    "        if cluster != []:\n",
    "            cluster.append(u)\n",
    "            solution.append(cluster)\n",
    "            AGraph.remove_nodes_from(cluster)\n",
    "#         print solution    \n",
    "        else: print weights[-1][1],threshold\n",
    "    if AGraph.number_of_nodes()>0: \n",
    "        solution.append(AGraph.nodes())\n",
    "    return solution\n",
    "\n",
    "# helper function\n",
    "def kwiksort_helper(AGraph,k,threshold, randomchoice = True):\n",
    "    # solution should be a list of lists or tuples\n",
    "    solution= []\n",
    "    fail = 0 \n",
    "    percentile = threshold\n",
    "    \n",
    "    ## Fill in here\n",
    "    while (AGraph.number_of_nodes()>k):\n",
    "        # dynamic threshold (70%tile)\n",
    "        dist = []\n",
    "        for edge in AGraph.edges_iter():\n",
    "            dist.append(AGraph.edge[edge[0]][edge[1]]['weight'])\n",
    "        threshold = np.percentile(dist, percentile)\n",
    "        \n",
    "        # sort neighbors according to weights \n",
    "        if randomchoice: \n",
    "            u = AGraph.nodes()[random.randint(0,AGraph.number_of_nodes()-1)]\n",
    "        else:\n",
    "            u = select_node(AGraph,k)\n",
    "            \n",
    "        neighbors = AGraph.neighbors(u)\n",
    "        weights = {}\n",
    "        for neighbor in neighbors:\n",
    "            weights[neighbor] = AGraph.edge[u][neighbor]['weight']\n",
    "        weights = sorted(weights.iteritems(), key=lambda (k,v): (v,k))[::-1]\n",
    "\n",
    "        # if found enough similar neighbors, form a cluster; o.w. choose another node\n",
    "        if weights[k-2][1] > threshold:\n",
    "            cluster = [x[0] for x in weights[:k-1]] + [u]\n",
    "            solution.append(cluster)\n",
    "            AGraph.remove_nodes_from(cluster)\n",
    "        else: \n",
    "            fail = fail+ 1\n",
    "            if fail > 20: return [] \n",
    "    \n",
    "    if AGraph.number_of_nodes()>0: \n",
    "        solution.append(AGraph.nodes())\n",
    "    return solution\n",
    "\n",
    "def select_node(AGraph,k):\n",
    "    maxweights = -1; choice = 0\n",
    "    for u in AGraph.nodes():\n",
    "        # sort neighbors according to weights \n",
    "        neighbors = AGraph.neighbors(u)\n",
    "        weights = []\n",
    "        for neighbor in neighbors:\n",
    "            weights.append(AGraph.edge[u][neighbor]['weight'])\n",
    "        weights = sorted(weights)[::-1]\n",
    "\n",
    "        # if found enough similar neighbors, form a cluster; o.w. choose another node\n",
    "        if sum(weights[:k-1]) > maxweights:\n",
    "            maxweights = sum(weights[:k-1])\n",
    "            choice = u\n",
    "    return choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CK_threshold_test(input_file,team_size,min_team_size,num_iter,threshold):\n",
    "    (data, features, person_features) = data_preprocessing(input_file)\n",
    "    pairs = findsubsets(features,2)\n",
    "    person_ids = list(features.keys())\n",
    "    \n",
    "    # creating similarity graph\n",
    "    AGraph = similarity_graph(features)    \n",
    "    \n",
    "    forplot =[]\n",
    "    \n",
    "    print '*'*50\n",
    "    con_kwik_rmsd = []\n",
    "    con_kwik_a = []; con_kwik_s = []; con_kwik_clusters_a = []; con_kwik_clusters_s = []\n",
    "    for j in range(10,100,5):\n",
    "        print 'threshold:',j, 'th percentile'\n",
    "        for i in range(6):\n",
    "            IAGraph = nx.Graph(AGraph)\n",
    "#             print 'Running constrained kwiksort for time:',i\n",
    "            solution = constrained_kwiksort(IAGraph,team_size,j)[:]\n",
    "#             print 'Computing Root Mean Square Deviation'\n",
    "            (score_RMSD,clusters_RMSD,idx_RMSD_CK) = rmsd(solution,features)\n",
    "            con_kwik_rmsd.append(score_RMSD)\n",
    "#             print 'Computing Silhouette Index'\n",
    "            (a_score,s_score,clusters_a,clusters_s,idx_a_CK,idx_s_CK) = silhouette_index(solution,features)\n",
    "            con_kwik_a.append(a_score); con_kwik_s.append(s_score) \n",
    "            con_kwik_clusters_a.append(clusters_a); con_kwik_clusters_s.append(clusters_s)\n",
    "        score_RMSD = sum(con_kwik_rmsd)/float(len(con_kwik_rmsd))\n",
    "        a_score = sum(con_kwik_a)/float(len(con_kwik_a)); s_score = sum(con_kwik_s)/float(len(con_kwik_s))\n",
    "        \n",
    "        print 'Root Mean Square Deviation for constrained kwiksort is:',score_RMSD\n",
    "        print 'A score for constrained kwiksort is:',a_score\n",
    "        print 'S score for constrained kwiksort is:',s_score\n",
    "        forplot.append([j,score_RMSD,a_score,s_score])\n",
    "    return forplot\n",
    "\n",
    "def CK_random_test(input_file,team_size,min_team_size,num_iter,threshold):\n",
    "    (data, features, person_features) = data_preprocessing(input_file)\n",
    "    pairs = findsubsets(features,2)\n",
    "    person_ids = list(features.keys())  \n",
    "    AGraph = similarity_graph(features)    \n",
    "\n",
    "    forplot =[]\n",
    "    \n",
    "    print '*'*50\n",
    "    con_kwik_rmsd = []\n",
    "    con_kwik_a = []; con_kwik_s = []; con_kwik_clusters_a = []; con_kwik_clusters_s = []\n",
    "    for j in [True, False]:\n",
    "        print 'random select nodes in each iteration:',j\n",
    "        for i in range(10):\n",
    "            IAGraph = nx.Graph(AGraph)\n",
    "#             print 'Running constrained kwiksort for time:',i\n",
    "            if j:\n",
    "                solution = constrained_kwiksort(IAGraph,team_size,70)[:]\n",
    "            else:\n",
    "                solution = constrained_kwiksort_not_random(IAGraph,team_size,70)[:]\n",
    "#             print 'Computing Root Mean Square Deviation'\n",
    "            (score_RMSD,clusters_RMSD,idx_RMSD_CK) = rmsd(solution,features)\n",
    "            con_kwik_rmsd.append(score_RMSD)\n",
    "#             print 'Computing Silhouette Index'\n",
    "            (a_score,s_score,clusters_a,clusters_s,idx_a_CK,idx_s_CK) = silhouette_index(solution,features)\n",
    "            con_kwik_a.append(a_score); con_kwik_s.append(s_score) \n",
    "            con_kwik_clusters_a.append(clusters_a); con_kwik_clusters_s.append(clusters_s)\n",
    "        score_RMSD = sum(con_kwik_rmsd)/float(len(con_kwik_rmsd))\n",
    "        a_score = sum(con_kwik_a)/float(len(con_kwik_a)); s_score = sum(con_kwik_s)/float(len(con_kwik_s))\n",
    "        \n",
    "        print 'Root Mean Square Deviation for constrained kwiksort is:',score_RMSD\n",
    "        print 'A score for constrained kwiksort is:',a_score\n",
    "        print 'S score for constrained kwiksort is:',s_score\n",
    "        forplot.append([j,score_RMSD,a_score,s_score])\n",
    "    return forplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pairwise(t):\n",
    "    pairs = list(itertools.combinations(t, 2))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsd(solution,features):\n",
    "    score = 0\n",
    "    # print 'Solution:',solution\n",
    "    # print 'Features:',features\n",
    "    rmsds = []; clusters_rmsd = []; idx_rmsd = {}\n",
    "    \n",
    "    for idx,team in enumerate(solution):\n",
    "        team_features = []; rmsds = []\n",
    "        for member in team:\n",
    "            team_features.append(features[member])\n",
    "        # team_features = np.array(team_features)\n",
    "        # team_features = team_features[:,7:15].tolist()\n",
    "        # team_features = team_features.tolist()\n",
    "        c = centroid(team_features)   \n",
    "        # print 'Centroid is:',c\n",
    "        for person in team_features:\n",
    "            # print 'Person is:',person\n",
    "            # print 'MSE:',mean_squared_error(person, c)\n",
    "            rms = sqrt(mean_squared_error(person, c))\n",
    "            # print 'RMS is:',rms\n",
    "            rmsds.append(rms)\n",
    "            \n",
    "        avg_per_cluster = sum(rmsds)/float(len(rmsds))\n",
    "        idx_rmsd[idx] = avg_per_cluster\n",
    "        # print 'Average cluster is:',avg_per_cluster\n",
    "        clusters_rmsd.append(avg_per_cluster)\n",
    "        # print\n",
    "    \n",
    "    \n",
    "    score = sum(clusters_rmsd)/float(len(clusters_rmsd))\n",
    "    # print 'RMSD Score:',score\n",
    "    return score,clusters_rmsd,idx_rmsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def silhouette_index(solution,features):\n",
    "    score = 0\n",
    "    a_precomp = {}; a = {}; avg_per_cluster = []; a_avg_of_clusters = []; s_avg_of_clusters = []\n",
    "    b_precomp = {}; b = {}; rms_per_user = []\n",
    "    s = {};\n",
    "    team_members = {}; non_team_members = {};\n",
    "    idx_a = {}; idx_b = {}; idx_s = {}\n",
    "    members = []; users = []\n",
    "    \n",
    "    # list of all users and team members\n",
    "    for idx,team in enumerate(solution):\n",
    "        for member in team:\n",
    "            users.append(member)\n",
    "            copy_team = list(team)\n",
    "            copy_team.remove(member)\n",
    "            remaining_team = copy_team\n",
    "            team_members[member] = remaining_team\n",
    "\n",
    "    # list of non-team members\n",
    "    for member in users:\n",
    "        team = team_members[member]\n",
    "        non_team = list(set(users) - set(team))\n",
    "        copy_team = list(non_team)\n",
    "        copy_team.remove(member)\n",
    "        non_team_members[member] = copy_team\n",
    "\n",
    "    # computing a - compactness\n",
    "    for idx,team in enumerate(solution):\n",
    "        if len(team) > 1:\n",
    "            pairs = pairwise(team) \n",
    "        else:\n",
    "            pairs = ((team[0],team[0]),)\n",
    "            \n",
    "        sum_sed = 0\n",
    "        for pair in pairs:\n",
    "            u1 = pair[0]; x = features[u1];\n",
    "            u2 = pair[1]; y = features[u2];\n",
    "            # rms = sqrt(mean_squared_error(x[7:15], y[7:15]))\n",
    "            rms = sqrt(mean_squared_error(x, y))\n",
    "            if u1 in a_precomp:\n",
    "                a_precomp[u1].append(rms)\n",
    "            else:\n",
    "                a_precomp[u1] = []\n",
    "                a_precomp[u1].append(rms)\n",
    "                \n",
    "            if u2 in a_precomp:\n",
    "                a_precomp[u2].append(rms)\n",
    "            else:\n",
    "                a_precomp[u2] = []\n",
    "                a_precomp[u2].append(rms)  \n",
    "        \n",
    "        for key,value in a_precomp.iteritems():\n",
    "            if len(team) > 1:\n",
    "                avg_per_user = sum(value)/float(len(team) - 1)\n",
    "            else:\n",
    "                avg_per_user = sum(value)/float(len(team))\n",
    "            # a(i)\n",
    "            a[key] = avg_per_user                \n",
    "            avg_per_cluster.append(avg_per_user)\n",
    "        \n",
    "        if avg_per_cluster:\n",
    "            avg_cluster = sum(avg_per_cluster)/float(len(avg_per_cluster))\n",
    "        else:\n",
    "            avg_cluster = 0\n",
    "            \n",
    "        idx_a[idx] = avg_cluster\n",
    "        a_avg_of_clusters.append(avg_cluster)\n",
    "        a_precomp = {}; avg_per_cluster = []\n",
    "    \n",
    "    a_score = sum(a_avg_of_clusters)/float(len(a_avg_of_clusters))\n",
    "    \n",
    "    # computing b - separation\n",
    "    for key,value in non_team_members.iteritems():\n",
    "        x = features[key]\n",
    "        for non_member in value:\n",
    "            y = features[non_member]\n",
    "            # rms = sqrt(mean_squared_error(x[7:15], y[7:15]))\n",
    "            rms = sqrt(mean_squared_error(x, y))\n",
    "            rms_per_user.append(rms)\n",
    "\n",
    "        min_dist = min(rms_per_user)\n",
    "        b[key] = min_dist\n",
    "        rms_per_user = []\n",
    "    \n",
    "    for key, value in a.iteritems():\n",
    "        # You want a to be small (distance from same cluster points)\n",
    "        # You want b to be large (distance from different cluster points)\n",
    "            \n",
    "        if b[key]!=a[key]:\n",
    "            s[key] = (b[key] - a[key])/float(max(b[key],a[key]))\n",
    "        else:\n",
    "            s[key] = 0 \n",
    "    \n",
    "    s_cluster = []; avg_clusters = []\n",
    "    for idx,team in enumerate(solution):\n",
    "        for member in team:\n",
    "            s_cluster.append(s[member])\n",
    "\n",
    "        cluster_avg = sum(s_cluster)/float(len(s_cluster))\n",
    "        idx_s[idx] = cluster_avg\n",
    "        s_avg_of_clusters.append(cluster_avg)\n",
    "        s_cluster = []\n",
    "    \n",
    "    s_score = sum(s_avg_of_clusters)/float(len(s_avg_of_clusters))\n",
    "    return (a_score,s_score,a_avg_of_clusters,s_avg_of_clusters,idx_a,idx_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    test_features = {}\n",
    "    test_features[1] = [2,1,1,3]; test_features[2] = [1,0,0,1]; test_features[5] = [1,0,0,1]\n",
    "    test_features[3] = [1,0,0,1]; test_features[4] = [1,1,0,0]\n",
    "    team1 = (1,2,5); team2 = (3,4)\n",
    "    test_solution = []; test_solution.append(team1); test_solution.append(team2)\n",
    "    (score_RMSD,clusters_RMSD) = rmsd(test_solution,test_features)\n",
    "    print 'Root Mean Square Deviation for constrained hierarchical is:',score_RMSD\n",
    "    (a_score,s_score,clusters_a,clusters_s) = silhouette_index(test_solution,test_features)\n",
    "    print 'A score for constrained hierarchical is:',a_score\n",
    "    print 'S score for constrained hierarchical is:',s_score\n",
    "    print 'A score cluster averages for constrained hierarchical is:',clusters_a\n",
    "    print 'S score cluster averages for constrained hierarchical is:',clusters_s\n",
    "    print 'Finished with test'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main(input_file,team_size,min_team_size,num_iter,threshold):\n",
    "    \n",
    "    # creating the feature vector\n",
    "    (data, features, person_features) = data_preprocessing(input_file)\n",
    "    pairs = findsubsets(features,2)\n",
    "    person_ids = list(features.keys())\n",
    "    \n",
    "    # creating similarity graph\n",
    "    AGraph = similarity_graph(features)  \n",
    "    \n",
    "    \n",
    "    # creating test sample for rmsd\n",
    "    # test()\n",
    "\n",
    "    IAGraph = nx.Graph(AGraph)\n",
    "    print 'Number of persons:',nx.number_of_nodes(IAGraph)\n",
    "    print 'Running constrained hierarchical'\n",
    "    solution = constrained_hierarchical(IAGraph,team_size)\n",
    "    counter = 0\n",
    "    for cluster in solution:\n",
    "        for person in cluster:\n",
    "            counter+=1\n",
    "            \n",
    "    print 'Solution persons:',counter\n",
    "    # print 'Solution:',solution\n",
    "    solution = assign_small_clusters(min_team_size,team_size,solution,features)\n",
    "    # print 'Solution',solution\n",
    "    print 'Computing Root Mean Square Deviation'\n",
    "    (score_RMSD,clusters_RMSD,idx_RMSD_CH) = rmsd(solution,features)\n",
    "    print 'Root Mean Square Deviation for constrained hierarchical is:',score_RMSD\n",
    "    print 'Computing Silhouette Index'\n",
    "    (a_score,s_score,clusters_a,clusters_s,idx_a_CH,idx_s_CH) = silhouette_index(solution,features)\n",
    "    print 'A score for constrained hierarchical is:',a_score\n",
    "    print 'S score for constrained hierarchical is:',s_score\n",
    "    print 'A score cluster averages for constrained hierarchical is:',clusters_a\n",
    "    print 'S score cluster averages for constrained hierarchical is:',clusters_s\n",
    "    # print 'Writing to file'\n",
    "    write_to_output(solution,person_features,idx_RMSD_CH,idx_a_CH,idx_s_CH,'BHConstrainedHierarch.csv')\n",
    "    \n",
    "    print '*'*50\n",
    "    IAGraph = nx.Graph(AGraph)\n",
    "    print 'Running unconstrained hierarchical'\n",
    "    solution = unconstrained_hierarchical(IAGraph,team_size)\n",
    "    \n",
    "    counter = 0\n",
    "    for cluster in solution:\n",
    "        for person in cluster:\n",
    "            counter+=1\n",
    "            \n",
    "    print 'Solution persons:',counter\n",
    "    print 'Computing Root Mean Square Deviation'\n",
    "    (score_RMSD,clusters_RMSD,idx_RMSD_UH) = rmsd(solution,features)\n",
    "    print 'Root Mean Square Deviation for unconstrained hierarchical is:',score_RMSD\n",
    "    print 'Computing Silhouette Index'\n",
    "    (a_score,s_score,clusters_a,clusters_s,idx_a_UH,idx_s_UH) = silhouette_index(solution,features)\n",
    "    print 'A score for unconstrained hierarchical is:',a_score\n",
    "    print 'S score for unconstrained hierarchical is:',s_score\n",
    "    print 'A score cluster averages for unconstrained hierarchical is:',clusters_a\n",
    "    print 'S score cluster averages for unconstrained hierarchical is:',clusters_s\n",
    "    # print 'Writing to file'\n",
    "    write_to_output(solution,person_features,idx_RMSD_UH,idx_a_UH,idx_s_UH,'BHUnconstrainedHierarch.csv')\n",
    "    \n",
    "    print '*'*50\n",
    "    con_kwik_rmsd = []\n",
    "    con_kwik_a = []; con_kwik_s = []; con_kwik_clusters_a = []; con_kwik_clusters_s = []\n",
    "    for i in range(6):\n",
    "        IAGraph = nx.Graph(AGraph)\n",
    "        print 'Running constrained kwiksort for time:',i\n",
    "        solution = constrained_kwiksort(IAGraph,team_size,70)\n",
    "        '''temperary: offset the cluster with size one \n",
    "        \n",
    "        '''\n",
    "        # solution = solution[:-1]\n",
    "        print 'Computing Root Mean Square Deviation'\n",
    "        (score_RMSD,clusters_RMSD,idx_RMSD_CK) = rmsd(solution,features)\n",
    "        con_kwik_rmsd.append(score_RMSD)\n",
    "        print 'Computing Silhouette Index'\n",
    "        (a_score,s_score,clusters_a,clusters_s,idx_a_CK,idx_s_CK) = silhouette_index(solution,features)\n",
    "        con_kwik_a.append(a_score); con_kwik_s.append(s_score) \n",
    "        con_kwik_clusters_a.append(clusters_a); con_kwik_clusters_s.append(clusters_s)\n",
    "    \n",
    "    score_RMSD = sum(con_kwik_rmsd)/float(len(con_kwik_rmsd))\n",
    "    a_score = sum(con_kwik_a)/float(len(con_kwik_a)); s_score = sum(con_kwik_s)/float(len(con_kwik_s))\n",
    "    print 'Root Mean Square Deviation for constrained kwiksort is:',score_RMSD\n",
    "    print 'A score for constrained kwiksort is:',a_score\n",
    "    print 'S score for constrained kwiksort is:',s_score\n",
    "    print 'A score cluster average indicative for constrained kwiksort is:',clusters_a\n",
    "    print 'S score cluster average indicative for constrained kwiksort is:',clusters_s\n",
    "    counter = 0\n",
    "    for cluster in solution:\n",
    "        for person in cluster:\n",
    "            counter+=1\n",
    "            \n",
    "    print 'Solution persons:',counter\n",
    "    write_to_output(solution,person_features,idx_RMSD_CK,idx_a_CK,idx_s_CK,'BHConstrainedKwiksort.csv')\n",
    "        \n",
    "#     print '*'*50\n",
    "#     uncon_kwik_rmsd = []\n",
    "#     uncon_kwik_a = []; uncon_kwik_s = []; uncon_kwik_clusters_a = []; uncon_kwik_clusters_s = []\n",
    "#     for i in range(2):\n",
    "#         IAGraph = nx.Graph(AGraph)\n",
    "#         print 'Running unconstrained kwiksort'\n",
    "#         solution = unconstrained_kwiksort(IAGraph,team_size,1/float(2.5))\n",
    "# #         print 'Solution:',[len(x) for x in solution]\n",
    "        \n",
    "#         '''temperary: offset the cluster with size one \n",
    "        \n",
    "#         '''\n",
    "#         solution = [x for x in solution if len(x)>1]\n",
    "\n",
    "#         print 'Computing Root Mean Square Deviation'\n",
    "#         (score_RMSD,clusters_RMSD,idx_RMSD_UK) = rmsd(solution,features)\n",
    "#         uncon_kwik_rmsd.append(score_RMSD)\n",
    "#         print 'Computing Silhouette Index'\n",
    "#         (a_score,s_score,clusters_a,clusters_s,idx_a_UK,idx_s_UK) = silhouette_index(solution,features)\n",
    "#         uncon_kwik_a.append(a_score); uncon_kwik_s.append(s_score) \n",
    "#         uncon_kwik_clusters_a.append(clusters_a); uncon_kwik_clusters_s.append(clusters_s)\n",
    "    \n",
    "#     score_RMSD = sum(uncon_kwik_rmsd)/float(len(uncon_kwik_rmsd))\n",
    "#     a_score = sum(uncon_kwik_a)/float(len(uncon_kwik_a)); s_score = sum(uncon_kwik_s)/float(len(uncon_kwik_s))\n",
    "#     print 'Root Mean Square Deviation for unconstrained kwiksort is:',score_RMSD\n",
    "#     print 'A score for unconstrained kwiksort is:',a_score\n",
    "#     print 'S score for unconstrained kwiksort is:',s_score\n",
    "#     print 'A score cluster average indicative for unconstrained kwiksort is:',clusters_a\n",
    "#     print 'S score cluster average indicative for unconstrained kwiksort is:',clusters_s\n",
    "#     write_to_output(solution,person_features,idx_RMSD_UK,idx_a_UK,idx_s_UK,'BHUnconstrainedKwiksort.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating aggreement graph\n",
      "Number of persons: 94\n",
      "Running constrained hierarchical\n",
      "Solution persons: 94\n",
      "Computing Root Mean Square Deviation\n",
      "Root Mean Square Deviation for constrained hierarchical is: 0.671762823998\n",
      "Computing Silhouette Index\n",
      "A score for constrained hierarchical is: 1.06487615811\n",
      "S score for constrained hierarchical is: -0.251262824236\n",
      "A score cluster averages for constrained hierarchical is: [1.2940223056003255, 1.346991700257765, 0.36141680516200214, 1.029805676495949, 1.276108627078605, 1.391002890790538, 0.9824939106968336, 1.2006282090974258, 1.1150761748914857, 0.9207656835226061, 1.124798217451069, 1.0370939187491648, 0.9567858169293382, 1.1462090735260708, 1.1313136193317113, 0.9652889920367569, 1.027195787344877, 0.9883336762645755, 0.9373159189498617]\n",
      "S score cluster averages for constrained hierarchical is: [-0.3909214275609673, -0.40772020044137103, 0.639995467050918, -0.26556405087611407, -0.4598026716234502, -0.3696514438084074, -0.282697991921177, -0.33165550753494005, -0.22424912016557674, -0.2913498129958233, -0.402015293176894, -0.27623609337920085, -0.25305081171028476, -0.2653113711202012, -0.28724544546391595, -0.22151643557681747, -0.2081905149707252, -0.24905613901686569, -0.22775479619398445]\n",
      "**************************************************\n",
      "Running unconstrained hierarchical\n",
      "Solution persons: 94\n",
      "Computing Root Mean Square Deviation\n",
      "Root Mean Square Deviation for unconstrained hierarchical is: 0.236409777493\n",
      "Computing Silhouette Index\n",
      "A score for unconstrained hierarchical is: 0.414523110082\n",
      "S score for unconstrained hierarchical is: 0.474614069133\n",
      "A score cluster averages for unconstrained hierarchical is: [1.1338934190276817, 1.029805676495949, 1.1897988870396967, 0.7423074889580902, 0.7824607964359516, 0.9793792286287205, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.2006282090974258, 0.0, 0.0, 0.0, 0.9793792286287205, 0.6700593942604899, 0.0, 0.0, 0.9567858169293382, 1.1440954050925451, 1.1605769149479943, 0.0, 0.5345224838248488, 0.0, 1.1768589882967777, 0.0, 0.0, 0.9431583929155366, 0.0, 0.0, 0.0, 0.7189056434643776, 0.0, 0.8921425711997711, 0.0, 0.8571428571428572, 0.0, 0.987827985131038, 0.9883336762645755, 0.0, 0.0]\n",
      "S score cluster averages for unconstrained hierarchical is: [-0.3134288270665889, -0.26556405087611407, -0.3154345740699534, 0.05827003255114649, -0.1992330139067682, -0.206596985430497, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -0.33165550753494005, 1.0, 1.0, 1.0, -0.3614319311860644, -0.02326870537720378, 1.0, 1.0, -0.25305081171028476, -0.032896049839643164, -0.3036893761772086, 1.0, 0.028069449343200735, 1.0, -0.4339658883814692, 1.0, 1.0, -0.379056807805902, 1.0, 1.0, 1.0, -0.05368908302147838, 1.0, -0.09175170953613694, 1.0, -0.11808289631180327, 1.0, -0.3222399445095176, -0.24905613901686569, 1.0, 1.0]\n",
      "**************************************************\n",
      "Running constrained kwiksort for time: 0\n",
      "feasible solution found\n",
      "Computing Root Mean Square Deviation\n",
      "Computing Silhouette Index\n",
      "Running constrained kwiksort for time: 1\n",
      "feasible solution found\n",
      "Computing Root Mean Square Deviation\n",
      "Computing Silhouette Index\n",
      "Running constrained kwiksort for time: 2\n",
      "feasible solution found\n",
      "Computing Root Mean Square Deviation\n",
      "Computing Silhouette Index\n",
      "Running constrained kwiksort for time: 3\n",
      "feasible solution found\n",
      "Computing Root Mean Square Deviation\n",
      "Computing Silhouette Index\n",
      "Running constrained kwiksort for time: 4\n",
      "feasible solution found\n",
      "Computing Root Mean Square Deviation\n",
      "Computing Silhouette Index\n",
      "Running constrained kwiksort for time: 5\n",
      "feasible solution found\n",
      "Computing Root Mean Square Deviation\n",
      "Computing Silhouette Index\n",
      "Root Mean Square Deviation for constrained kwiksort is: 0.709015245137\n",
      "A score for constrained kwiksort is: 1.11836920021\n",
      "S score for constrained kwiksort is: -0.29879839785\n",
      "A score cluster average indicative for constrained kwiksort is: [0.9516492643597582, 0.9567858169293382, 0.8376185834930627, 1.2270214134062978, 0.7914689705837347, 1.1271923122474534, 1.1321216756775776, 1.0028608501465412, 0.8572433685990134, 0.9143037013308535, 1.1608365990411804, 1.0045728000652903, 1.1618925618682818, 1.2700788772963658, 1.3050788278802041, 0.9323823164662464, 1.2296507505640393, 1.4509258313643576, 1.454754884248593]\n",
      "S score cluster average indicative for constrained kwiksort is: [-0.3201469773778626, -0.25305081171028476, -0.2560218979882244, -0.3137894149070564, -0.14881923188192775, -0.2335052062994531, -0.3722996457564106, -0.38841150006006375, -0.13871429235053195, 0.15849576976595364, -0.43057615090866613, -0.22369416737306827, -0.27734672074023964, -0.3459223959216592, -0.3770141566352364, -0.21055306720404537, -0.3909780880229984, -0.41084188626554063, -0.2895483927817455]\n",
      "Solution persons: 94\n"
     ]
    }
   ],
   "source": [
    "# Team constraints: 1) Each team is a team of approximately 5 2) Similar users and interests are grouped together \n",
    "input_file = 'Bostonhacks_clean(s).csv'\n",
    "dataset_file = 'boston_dataset.csv'\n",
    "num_iter = 1\n",
    "threshold = 1/float(100)\n",
    "# Removing first empty row from dataset -- TODO\n",
    "with open(input_file,'r') as f, open(dataset_file,'w') as f1:\n",
    "    # next(f) # skip header line\n",
    "    for line in f:\n",
    "        f1.write(line)\n",
    "        \n",
    "data = pd.read_csv(dataset_file)    \n",
    "\n",
    "max_team_size = 5\n",
    "min_team_size = 4\n",
    "main(dataset_file, max_team_size, min_team_size, num_iter, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Below is for testing the effect of different percentile on Constrained Kwiksort</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating aggreement graph\n",
      "**************************************************\n",
      "random select nodes in each iteration: True\n",
      "feasible solution found\n",
      "feasible solution found\n",
      "feasible solution found\n",
      "feasible solution found\n",
      "feasible solution found\n",
      "feasible solution found\n",
      "feasible solution found\n",
      "feasible solution found\n",
      "feasible solution found\n",
      "feasible solution found\n",
      "Root Mean Square Deviation for constrained kwiksort is: 0.704140641275\n",
      "A score for constrained kwiksort is: 1.11174928482\n",
      "S score for constrained kwiksort is: -0.303953165817\n",
      "random select nodes in each iteration: False\n",
      "feasible solution found\n",
      "feasible solution found\n",
      "feasible solution found\n",
      "feasible solution found\n",
      "feasible solution found\n",
      "feasible solution found\n",
      "feasible solution found\n",
      "feasible solution found\n",
      "feasible solution found\n",
      "feasible solution found\n",
      "Root Mean Square Deviation for constrained kwiksort is: 0.687761654502\n",
      "A score for constrained kwiksort is: 1.08660425111\n",
      "S score for constrained kwiksort is: -0.277488213818\n"
     ]
    }
   ],
   "source": [
    "forplot = CK_random_test(dataset_file, max_team_size, min_team_size, num_iter, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAEKCAYAAAAsIk01AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113aefd90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = np.array(forplot)\n",
    "plt.plot(temp[:,0],temp[:,1], label=\"RMSD\")\n",
    "plt.plot(temp[:,0],temp[:,2],label=\"a_score\")\n",
    "plt.plot(temp[:,0],temp[:,3],label=\"s_score\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.ylim = (0,0.2)\n",
    "plt.xlabel('percentile as threshold')\n",
    "plt.ylabel('evaluation metric ')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
